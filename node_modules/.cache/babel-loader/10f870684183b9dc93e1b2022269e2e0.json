{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\nimport { createFragmentMap, getFragmentFromSelection, getDefaultValues, getFragmentDefinitions, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, hasDirectives, cloneDeep } from \"../../utilities/index.js\";\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from \"./helpers.js\";\n;\n\nvar StoreWriter = function () {\n  function StoreWriter(cache, reader) {\n    this.cache = cache;\n    this.reader = reader;\n  }\n\n  StoreWriter.prototype.writeToStore = function (_a) {\n    var query = _a.query,\n        result = _a.result,\n        dataId = _a.dataId,\n        store = _a.store,\n        variables = _a.variables;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: {\n        store: store,\n        written: Object.create(null),\n        merge: function merge(existing, incoming) {\n          return merger.merge(existing, incoming);\n        },\n        variables: variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query))\n      }\n    });\n\n    if (!isReference(ref)) {\n      throw process.env.NODE_ENV === \"production\" ? new InvariantError(7) : new InvariantError(\"Could not identify object \" + JSON.stringify(result));\n    }\n\n    store.retain(ref.__ref);\n    return ref;\n  };\n\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n\n    var dataId = _a.dataId,\n        result = _a.result,\n        selectionSet = _a.selectionSet,\n        context = _a.context,\n        mergeTree = _a.mergeTree;\n    var policies = this.cache.policies;\n\n    var _b = policies.identify(result, selectionSet, context.fragmentMap),\n        id = _b[0],\n        keyObject = _b[1];\n\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      var ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      if (this.reader && this.reader.isFresh(result, ref, selectionSet, context)) {\n        return ref;\n      }\n    }\n\n    var incomingFields = Object.create(null);\n\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    var workSet = new Set(selectionSet.selections);\n    workSet.forEach(function (selection) {\n      var _a;\n\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        var resultFieldKey = resultKeyNameFromField(selection);\n        var value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          var storeFieldName = policies.getStoreFieldName({\n            typename: typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables\n          });\n          var childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          var incomingValue = _this.processFieldValue(value, selection, context, childTree);\n\n          var childTypename = selection.selectionSet && context.store.getFieldValue(incomingValue, \"__typename\") || void 0;\n          var merge = policies.getMergeFunction(typename, selection.name.value, childTypename);\n\n          if (merge) {\n            childTree.info = {\n              field: selection,\n              typename: typename,\n              merge: merge\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n        } else if (policies.usingPossibleTypes && !hasDirectives([\"defer\", \"client\"], selection)) {\n          throw process.env.NODE_ENV === \"production\" ? new InvariantError(8) : new InvariantError(\"Missing field '\" + resultFieldKey + \"' in \" + JSON.stringify(result, null, 2).substring(0, 100));\n        }\n      } else {\n        var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n\n        if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      var entityRef_1 = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef_1, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        var hasSelectionSet_1 = function hasSelectionSet_1(storeFieldName) {\n          return fieldsWithSelectionSets_1.has(fieldNameFromStoreName(storeFieldName));\n        };\n\n        var fieldsWithSelectionSets_1 = new Set();\n        workSet.forEach(function (selection) {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets_1.add(selection.name.value);\n          }\n        });\n\n        var hasMergeFunction_1 = function hasMergeFunction_1(storeFieldName) {\n          var childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(function (storeFieldName) {\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef_1, incomingFields, storeFieldName, context.store);\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n      return entityRef_1;\n    }\n\n    return incomingFields;\n  };\n\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n\n    if (!field.selectionSet || value === null) {\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  };\n\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n\n    var _this = this;\n\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = !Array.isArray(incoming) && (isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      var i_1 = incoming;\n\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      }\n\n      var changedFields_1;\n\n      var getValue_1 = function getValue_1(from, name) {\n        return Array.isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName);\n\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields_1) {\n        incoming = Array.isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n\n    return incoming;\n  };\n\n  return StoreWriter;\n}();\n\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\n\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n\n  return map.get(name);\n}\n\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n\n  if (childTree && !childTree.info && !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nvar warnings = new Set();\n\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function getChild(objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return;\n  if (isReference(existing)) return;\n  if (equal(existing, incoming)) return;\n\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = parentType + \".\" + fieldName;\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = [];\n\n  if (!Array.isArray(existing) && !Array.isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  process.env.NODE_ENV === \"production\" || invariant.warn(\"Cache data may be lost when replacing the \" + fieldName + \" field of a \" + parentType + \" object.\\n\\nTo address this problem (which is not a bug in Apollo Client), \" + (childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\") + \"define a custom merge function for the \" + typeDotName + \" field, so InMemoryCache can safely merge these objects:\\n\\n  existing: \" + JSON.stringify(existing).slice(0, 1000) + \"\\n  incoming: \" + JSON.stringify(incoming).slice(0, 1000) + \"\\n\\nFor more information about these options, please refer to the documentation:\\n\\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\\n\");\n}","map":{"version":3,"sources":["../../../src/cache/inmemory/writeToStore.ts"],"names":[],"mappings":";AACA,SAAS,SAAT,EAAoB,cAApB,QAA0C,cAA1C;AACA,SAAS,KAAT,QAAsB,eAAtB;AAEA,SACE,iBADF,EAGE,wBAHF,EAIE,gBAJF,EAKE,sBALF,EAME,sBANF,EAOE,qBAPF,EAQE,aARF,EASE,OATF,EAUE,sBAVF,EAcE,WAdF,EAeE,aAfF,EAgBE,aAhBF,EAiBE,SAjBF,QAkBO,0BAlBP;AAqBA,SAAS,yBAAT,EAAoC,sBAApC,EAA4D,uBAA5D,QAA2F,cAA3F;AAYC;;AAkBD,IAAA,WAAA,GAAA,YAAA;EACE,SAAA,WAAA,CACkB,KADlB,EAEU,MAFV,EAE8B;IADZ,KAAA,KAAA,GAAA,KAAA;IACR,KAAA,MAAA,GAAA,MAAA;EACN;;EAgBG,WAAA,CAAA,SAAA,CAAA,YAAA,GAAP,UAAoB,EAApB,EAMsB;QALpB,KAAK,GAAA,EAAA,CAAA,K;QACL,MAAM,GAAA,EAAA,CAAA,M;QACN,MAAM,GAAA,EAAA,CAAA,M;QACN,KAAK,GAAA,EAAA,CAAA,K;QACL,SAAS,GAAA,EAAA,CAAA,S;IAET,IAAM,mBAAmB,GAAG,sBAAsB,CAAC,KAAD,CAAlD;IACA,IAAM,MAAM,GAAG,yBAAyB,EAAxC;IAEA,SAAS,GAAA,QAAA,CAAA,QAAA,CAAA,EAAA,EACJ,gBAAgB,CAAC,mBAAD,CADZ,CAAA,EAEJ,SAFI,CAAT;IAKA,IAAM,GAAG,GAAG,KAAK,mBAAL,CAAyB;MACnC,MAAM,EAAE,MAAM,IAAI,MAAM,CAAC,MAAP,CAAc,IAAd,CADiB;MAEnC,MAAM,EAAA,MAF6B;MAGnC,YAAY,EAAE,mBAAmB,CAAC,YAHC;MAInC,SAAS,EAAE;QAAE,GAAG,EAAE,IAAI,GAAJ;MAAP,CAJwB;MAKnC,OAAO,EAAE;QACP,KAAK,EAAA,KADE;QAEP,OAAO,EAAE,MAAM,CAAC,MAAP,CAAc,IAAd,CAFF;QAGP,KAAK,EAAL,eAAS,QAAT,EAAsB,QAAtB,EAAiC;UAC/B,OAAO,MAAM,CAAC,KAAP,CAAa,QAAb,EAAuB,QAAvB,CAAP;QACD,CALM;QAMP,SAAS,EAAA,SANF;QAOP,SAAS,EAAE,IAAI,CAAC,SAAL,CAAe,SAAf,CAPJ;QAQP,WAAW,EAAE,iBAAiB,CAAC,sBAAsB,CAAC,KAAD,CAAvB;MARvB;IAL0B,CAAzB,CAAZ;;IAiBA,IAAI,CAAC,WAAW,CAAC,GAAD,CAAhB,EAAuB;MACrB,MAAM,OAAI,CAAA,GAAJ,CAAI,QAAJ,KAAmB,YAAnB,GAAmB,IAAA,cAAA,CAAkC,CAAlC,CAAnB,GAA8D,IAAC,cAAD,CAAY,+BAAA,IAAA,CAAA,SAAA,CAAA,MAAA,CAAZ,CAApE;IACD;;IAOD,KAAK,CAAC,MAAN,CAAa,GAAG,CAAC,KAAjB;IAEA,OAAO,GAAP;EACD,CA5CM;;EA8CC,WAAA,CAAA,SAAA,CAAA,mBAAA,GAAR,UAA4B,EAA5B,EAQ6B;IAR7B,IAAA,KAAA,GAAA,IAAA;;QACE,MAAM,GAAA,EAAA,CAAA,M;QACN,MAAM,GAAA,EAAA,CAAA,M;QACN,YAAY,GAAA,EAAA,CAAA,Y;QACZ,OAAO,GAAA,EAAA,CAAA,O;QAGP,SAAS,GAAA,EAAA,CAAA,S;IAED,IAAA,QAAQ,GAAK,KAAK,KAAL,CAAL,QAAR;;IAIF,IAAA,EAAA,GAAkB,QAAQ,CAAC,QAAT,CACtB,MADsB,EACd,YADc,EACA,OAAO,CAAC,WADR,CAAlB;IAAA,IAAC,EAAE,GAAA,EAAA,CAAA,CAAA,CAAH;IAAA,IAAK,SAAS,GAAA,EAAA,CAAA,CAAA,CAAd;;IAKN,MAAM,GAAG,MAAM,IAAI,EAAnB;;IAEA,IAAI,aAAa,OAAO,MAAxB,EAAgC;MAM9B,IAAM,IAAI,GAAG,OAAO,CAAC,OAAR,CAAgB,MAAhB,MAA4B,OAAO,CAAC,OAAR,CAAgB,MAAhB,IAA0B,EAAtD,CAAb;MACA,IAAM,GAAG,GAAG,aAAa,CAAC,MAAD,CAAzB;MACA,IAAI,IAAI,CAAC,OAAL,CAAa,YAAb,KAA8B,CAAlC,EAAqC,OAAO,GAAP;MACrC,IAAI,CAAC,IAAL,CAAU,YAAV;;MAOA,IAAI,KAAK,MAAL,IAAe,KAAK,MAAL,CAAY,OAAZ,CACjB,MADiB,EAEjB,GAFiB,EAGjB,YAHiB,EAIjB,OAJiB,CAAnB,EAKG;QACD,OAAO,GAAP;MACD;IACF;;IAID,IAAI,cAAc,GAAgB,MAAM,CAAC,MAAP,CAAc,IAAd,CAAlC;;IAIA,IAAI,SAAJ,EAAe;MACb,cAAc,GAAG,OAAO,CAAC,KAAR,CAAc,cAAd,EAA8B,SAA9B,CAAjB;IACD;;IAKD,IAAM,QAAQ,GACX,MAAM,IAAI,QAAQ,CAAC,iBAAT,CAA2B,MAA3B,CAAX,IACA,qBAAqB,CAAC,MAAD,EAAS,YAAT,EAAuB,OAAO,CAAC,WAA/B,CADrB,IAEC,MAAM,IAAI,OAAO,CAAC,KAAR,CAAc,GAAd,CAAkB,MAAlB,EAA0B,YAA1B,CAHb;;IAKA,IAAI,aAAa,OAAO,QAAxB,EAAkC;MAChC,cAAc,CAAC,UAAf,GAA4B,QAA5B;IACD;;IAED,IAAM,OAAO,GAAG,IAAI,GAAJ,CAAQ,YAAY,CAAC,UAArB,CAAhB;IAEA,OAAO,CAAC,OAAR,CAAgB,UAAA,SAAA,EAAS;;;MACvB,IAAI,CAAC,aAAa,CAAC,SAAD,EAAY,OAAO,CAAC,SAApB,CAAlB,EAAkD;;MAElD,IAAI,OAAO,CAAC,SAAD,CAAX,EAAwB;QACtB,IAAM,cAAc,GAAG,sBAAsB,CAAC,SAAD,CAA7C;QACA,IAAM,KAAK,GAAG,MAAM,CAAC,cAAD,CAApB;;QAEA,IAAI,OAAO,KAAP,KAAiB,WAArB,EAAkC;UAChC,IAAM,cAAc,GAAG,QAAQ,CAAC,iBAAT,CAA2B;YAChD,QAAQ,EAAA,QADwC;YAEhD,SAAS,EAAE,SAAS,CAAC,IAAV,CAAe,KAFsB;YAGhD,KAAK,EAAE,SAHyC;YAIhD,SAAS,EAAE,OAAO,CAAC;UAJ6B,CAA3B,CAAvB;UAOA,IAAM,SAAS,GAAG,iBAAiB,CAAC,SAAD,EAAY,cAAZ,CAAnC;;UAEA,IAAI,aAAa,GACf,KAAI,CAAC,iBAAL,CAAuB,KAAvB,EAA8B,SAA9B,EAAyC,OAAzC,EAAkD,SAAlD,CADF;;UAGA,IAAM,aAAa,GAAG,SAAS,CAAC,YAAV,IACjB,OAAO,CAAC,KAAR,CAAc,aAAd,CAAoC,aAApC,EAAkE,YAAlE,CADiB,IAEjB,KAAK,CAFV;UAIA,IAAM,KAAK,GAAG,QAAQ,CAAC,gBAAT,CACZ,QADY,EAEZ,SAAS,CAAC,IAAV,CAAe,KAFH,EAGZ,aAHY,CAAd;;UAMA,IAAI,KAAJ,EAAW;YACT,SAAS,CAAC,IAAV,GAAiB;cAGf,KAAK,EAAE,SAHQ;cAIf,QAAQ,EAAA,QAJO;cAKf,KAAK,EAAA;YALU,CAAjB;UAOD,CARD,MAQO;YACL,0BAA0B,CAAC,SAAD,EAAY,cAAZ,CAA1B;UACD;;UAED,cAAc,GAAG,OAAO,CAAC,KAAR,CAAc,cAAd,GAA4B,EAAA,GAAA,EAAA,EAC3C,EAAA,CAAC,cAAD,CAAA,GAAkB,aADyB,EAE3C,EAFe,EAAjB;QAID,CAvCD,MAuCO,IACL,QAAQ,CAAC,kBAAT,IACA,CAAC,aAAa,CAAC,CAAC,OAAD,EAAU,QAAV,CAAD,EAAsB,SAAtB,CAFT,EAGL;UACA,MAAM,OAAI,CAAA,GAAJ,CAAI,QAAJ,KACJ,YADI,GACc,IAAA,cAAA,CAAc,CAAd,CADd,GAC4B,IAAQ,cAAR,CAC9B,oBAGA,cAHA,GAIF,OAJE,GAIF,IAAA,CAAA,SAAA,CAAA,MAAA,EAAA,IAAA,EAAA,CAAA,EAAA,SAAA,CAAA,CAAA,EAAA,GAAA,CALgC,CADlC;QAOD;MACF,CAvDD,MAuDO;QAEL,IAAM,QAAQ,GAAG,wBAAwB,CACvC,SADuC,EAEvC,OAAO,CAAC,WAF+B,CAAzC;;QAKA,IAAI,QAAQ,IAmBR,QAAQ,CAAC,eAAT,CAAyB,QAAzB,EAAmC,QAAnC,EAA6C,MAA7C,EAAqD,OAAO,CAAC,SAA7D,CAnBJ,EAmB6E;UAC3E,QAAQ,CAAC,YAAT,CAAsB,UAAtB,CAAiC,OAAjC,CAAyC,OAAO,CAAC,GAAjD,EAAsD,OAAtD;QACD;MACF;IACF,CAxFD;;IA0FA,IAAI,aAAa,OAAO,MAAxB,EAAgC;MAC9B,IAAM,WAAS,GAAG,aAAa,CAAC,MAAD,CAA/B;;MAEA,IAAI,SAAS,CAAC,GAAV,CAAc,IAAlB,EAAwB;QACtB,cAAc,GAAG,KAAK,WAAL,CAAiB,SAAjB,EAA4B,WAA5B,EAAuC,cAAvC,EAAuD,OAAvD,CAAjB;MACD;;MAED,IAAI,OAAO,CAAC,GAAR,CAAY,QAAZ,KAAyB,YAA7B,EAA2C;QACzC,IAAM,iBAAe,GAAG,SAAlB,iBAAkB,CAAC,cAAD,EAAuB;UAC7C,OAAA,yBAAuB,CAAC,GAAxB,CAA4B,sBAAsB,CAAC,cAAD,CAAlD,CAAA;QAAmE,CADrE;;QAEA,IAAM,yBAAuB,GAAG,IAAI,GAAJ,EAAhC;QACA,OAAO,CAAC,OAAR,CAAgB,UAAA,SAAA,EAAS;UACvB,IAAI,OAAO,CAAC,SAAD,CAAP,IAAsB,SAAS,CAAC,YAApC,EAAkD;YAChD,yBAAuB,CAAC,GAAxB,CAA4B,SAAS,CAAC,IAAV,CAAe,KAA3C;UACD;QACF,CAJD;;QAMA,IAAM,kBAAgB,GAAG,SAAnB,kBAAmB,CAAC,cAAD,EAAuB;UAC9C,IAAM,SAAS,GAAG,SAAS,CAAC,GAAV,CAAc,GAAd,CAAkB,cAAlB,CAAlB;UACA,OAAO,OAAO,CAAC,SAAS,IAAI,SAAS,CAAC,IAAvB,IAA+B,SAAS,CAAC,IAAV,CAAe,KAA/C,CAAd;QACD,CAHD;;QAKA,MAAM,CAAC,IAAP,CAAY,cAAZ,EAA4B,OAA5B,CAAoC,UAAA,cAAA,EAAc;UAKhD,IAAI,iBAAe,CAAC,cAAD,CAAf,IACA,CAAC,kBAAgB,CAAC,cAAD,CADrB,EACuC;YACrC,iBAAiB,CACf,WADe,EAEf,cAFe,EAGf,cAHe,EAIf,OAAO,CAAC,KAJO,CAAjB;UAMD;QACF,CAdD;MAeD;;MAED,OAAO,CAAC,KAAR,CAAc,KAAd,CAAoB,MAApB,EAA4B,cAA5B;MAEA,OAAO,WAAP;IACD;;IAED,OAAO,cAAP;EACD,CA7MO;;EA+MA,WAAA,CAAA,SAAA,CAAA,iBAAA,GAAR,UACE,KADF,EAEE,KAFF,EAGE,OAHF,EAIE,SAJF,EAIsB;IAJtB,IAAA,KAAA,GAAA,IAAA;;IAME,IAAI,CAAC,KAAK,CAAC,YAAP,IAAuB,KAAK,KAAK,IAArC,EAA2C;MAIzC,OAAO,OAAO,CAAC,GAAR,CAAY,QAAZ,KAAyB,YAAzB,GAAwC,KAAxC,GAAgD,SAAS,CAAC,KAAD,CAAhE;IACD;;IAED,IAAI,KAAK,CAAC,OAAN,CAAc,KAAd,CAAJ,EAA0B;MACxB,OAAO,KAAK,CAAC,GAAN,CAAU,UAAC,IAAD,EAAO,CAAP,EAAQ;QACvB,IAAM,KAAK,GAAG,KAAI,CAAC,iBAAL,CACZ,IADY,EACN,KADM,EACC,OADD,EACU,iBAAiB,CAAC,SAAD,EAAY,CAAZ,CAD3B,CAAd;;QAEA,0BAA0B,CAAC,SAAD,EAAY,CAAZ,CAA1B;QACA,OAAO,KAAP;MACD,CALM,CAAP;IAMD;;IAED,OAAO,KAAK,mBAAL,CAAyB;MAC9B,MAAM,EAAE,KADsB;MAE9B,YAAY,EAAE,KAAK,CAAC,YAFU;MAG9B,OAAO,EAAA,OAHuB;MAI9B,SAAS,EAAA;IAJqB,CAAzB,CAAP;EAMD,CA5BO;;EA8BA,WAAA,CAAA,SAAA,CAAA,WAAA,GAAR,UACE,SADF,EAEE,QAFF,EAGE,QAHF,EAIE,OAJF,EAKE,cALF,EAKwD;;;IALxD,IAAA,KAAA,GAAA,IAAA;;IAOE,IAAI,SAAS,CAAC,GAAV,CAAc,IAAd,IAAsB,CAAC,WAAW,CAAC,QAAD,CAAtC,EAAkD;MAChD,IAAM,GAAC,GAIL,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CAAD,KAIC,WAAW,CAAC,QAAD,CAAX,IAAyB,uBAAuB,CAAC,QAAD,CAJjD,CAJ6C,GAS3C,QAT2C,GAShC,KAAK,CATpB;MAcA,IAAM,GAAC,GAAG,QAAV;;MAMA,IAAI,GAAC,IAAI,CAAC,cAAV,EAA0B;QACxB,cAAc,GAAG,CAAC,WAAW,CAAC,GAAD,CAAX,GAAiB,GAAC,CAAC,KAAnB,GAA2B,GAA5B,CAAjB;MACD;;MAOD,IAAI,eAAJ;;MAEA,IAAM,UAAQ,GAAG,SAAX,UAAW,CACf,IADe,EAEf,IAFe,EAEM;QAErB,OAAO,KAAK,CAAC,OAAN,CAAc,IAAd,IACF,OAAO,IAAP,KAAgB,QAAhB,GAA2B,IAAI,CAAC,IAAD,CAA/B,GAAwC,KAAK,CAD3C,GAEH,OAAO,CAAC,KAAR,CAAc,aAAd,CAA4B,IAA5B,EAAkC,MAAM,CAAC,IAAD,CAAxC,CAFJ;MAGD,CAPD;;MASA,SAAS,CAAC,GAAV,CAAc,OAAd,CAAsB,UAAC,SAAD,EAAY,cAAZ,EAA0B;QAC9C,IAAI,cAAJ,EAAoB;UAClB,cAAc,CAAC,IAAf,CAAoB,cAApB;QACD;;QACD,IAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB;QACA,IAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB;;QACA,IAAM,IAAI,GAAG,KAAI,CAAC,WAAL,CACX,SADW,EAEX,IAFW,EAGX,IAHW,EAIX,OAJW,EAKX,cALW,CAAb;;QAOA,IAAI,IAAI,KAAK,IAAb,EAAmB;UACjB,eAAa,GAAG,eAAa,IAAI,IAAI,GAAJ,EAAjC;UACA,eAAa,CAAC,GAAd,CAAkB,cAAlB,EAAkC,IAAlC;QACD;;QACD,IAAI,cAAJ,EAAoB;UAClB,SAAS,CAAC,cAAc,CAAC,GAAf,OAAyB,cAA1B,CAAT;QACD;MACF,CApBD;;MAsBA,IAAI,eAAJ,EAAmB;QAEjB,QAAQ,GAAI,KAAK,CAAC,OAAN,CAAc,GAAd,IAAmB,GAAC,CAAC,KAAF,CAAQ,CAAR,CAAnB,GAA+B,QAAA,CAAA,EAAA,EAAM,GAAN,CAA3C;QACA,eAAa,CAAC,OAAd,CAAsB,UAAC,KAAD,EAAQ,IAAR,EAAY;UAC/B,QAAgB,CAAC,IAAD,CAAhB,GAAyB,KAAzB;QACF,CAFD;MAGD;IACF;;IAED,IAAI,SAAS,CAAC,IAAd,EAAoB;MAClB,OAAO,KAAK,KAAL,CAAW,QAAX,CAAoB,gBAApB,CACL,QADK,EAEL,QAFK,EAGL,SAAS,CAAC,IAHL,EAIL,OAJK,EAKL,cAAc,IAAI,CAAA,EAAA,GAAA,OAAO,CAAC,KAAR,EAAc,UAAd,CAAwB,KAAxB,CAAwB,EAAxB,EAA4B,cAA5B,CALb,CAAP;IAOD;;IAED,OAAO,QAAP;EACD,CA1FO;;EA2FV,OAAA,WAAA;AAAC,CA1YD,EAAA;;;AA4YA,IAAM,kBAAkB,GAAgB,EAAxC;;AAEA,SAAS,iBAAT,CACE,EADF,EAEE,IAFF,EAEuB;MADnB,GAAG,GAAA,EAAA,CAAA,G;;EAGL,IAAI,CAAC,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAL,EAAoB;IAClB,GAAG,CAAC,GAAJ,CAAQ,IAAR,EAAc,kBAAkB,CAAC,GAAnB,MAA4B;MAAE,GAAG,EAAE,IAAI,GAAJ;IAAP,CAA1C;EACD;;EACD,OAAO,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAP;AACD;;AAED,SAAS,0BAAT,CACE,EADF,EAEE,IAFF,EAEuB;MADnB,GAAG,GAAA,EAAA,CAAA,G;EAGL,IAAM,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAlB;;EACA,IAAI,SAAS,IACT,CAAC,SAAS,CAAC,IADX,IAEA,CAAC,SAAS,CAAC,GAAV,CAAc,IAFnB,EAEyB;IACvB,kBAAkB,CAAC,IAAnB,CAAwB,SAAxB;IACA,GAAG,CAAC,MAAJ,CAAW,IAAX;EACD;AACF;;AAED,IAAM,QAAQ,GAAG,IAAI,GAAJ,EAAjB;;AAIA,SAAS,iBAAT,CACE,WADF,EAEE,WAFF,EAGE,cAHF,EAIE,KAJF,EAIwB;EAEtB,IAAM,QAAQ,GAAG,SAAX,QAAW,CAAC,QAAD,EAAkC;IACjD,IAAM,KAAK,GAAG,KAAK,CAAC,aAAN,CAAiC,QAAjC,EAA2C,cAA3C,CAAd;IACA,OAAO,OAAO,KAAP,KAAiB,QAAjB,IAA6B,KAApC;EACD,CAHD;;EAKA,IAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;EACA,IAAI,CAAC,QAAL,EAAe;EAEf,IAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;EACA,IAAI,CAAC,QAAL,EAAe;EAIf,IAAI,WAAW,CAAC,QAAD,CAAf,EAA2B;EAI3B,IAAI,KAAK,CAAC,QAAD,EAAW,QAAX,CAAT,EAA+B;;EAK/B,IAAI,MAAM,CAAC,IAAP,CAAY,QAAZ,EAAsB,KAAtB,CACF,UAAA,GAAA,EAAG;IAAI,OAAA,KAAK,CAAC,aAAN,CAAoB,QAApB,EAA8B,GAA9B,MAAuC,KAAvC,CAAA;EAA6C,CADlD,CAAJ,EACyD;IACvD;EACD;;EAED,IAAM,UAAU,GACd,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,KACA,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,CAFF;EAGA,IAAM,SAAS,GAAG,sBAAsB,CAAC,cAAD,CAAxC;EACA,IAAM,WAAW,GAAM,UAAU,GAAA,GAAV,GAAc,SAArC;EAEA,IAAI,QAAQ,CAAC,GAAT,CAAa,WAAb,CAAJ,EAA+B;EAC/B,QAAQ,CAAC,GAAT,CAAa,WAAb;EAEA,IAAM,cAAc,GAAa,EAAjC;;EAGA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CAAD,IACA,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CADL,EAC8B;IAC5B,CAAC,QAAD,EAAW,QAAX,EAAqB,OAArB,CAA6B,UAAA,KAAA,EAAK;MAChC,IAAM,QAAQ,GAAG,KAAK,CAAC,aAAN,CAAoB,KAApB,EAA2B,YAA3B,CAAjB;;MACA,IAAI,OAAO,QAAP,KAAoB,QAApB,IACA,CAAC,cAAc,CAAC,QAAf,CAAwB,QAAxB,CADL,EACwC;QACtC,cAAc,CAAC,IAAf,CAAoB,QAApB;MACD;IACF,CAND;EAOD;;EAED,OAAA,CAAA,GAAA,CAAU,QAAV,KACF,YADE,IACF,SAAA,CAAA,IAAA,CAAA,+CAA+E,SAA/E,GAA+E,cAA/E,GAA+E,UAA/E,GAA+E,6EAA/E,IAGuB,cAAA,CAAA,MAAA,GACjB,uCACE,cAAc,CAAC,IAAf,CAAoB,OAApB,CADF,GACiC,6CAFhB,GAGjB,EANN,IAMQ,yCANR,GAQE,WARF,GAQa,0EARb,GAWc,IAAI,CAAC,SAAL,CAAe,QAAf,EAAyB,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAXd,GAWqD,gBAXrD,GAYc,IAAI,CAAC,SAAL,CAAe,QAAf,EAAyB,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAZd,GAYqD,gRAZrD,CADE;AAoBD","sourcesContent":["import { SelectionSetNode, FieldNode, DocumentNode } from 'graphql';\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  hasDirectives,\n  cloneDeep,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n};\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport interface WriteToStoreOptions {\n  query: DocumentNode;\n  result: Object;\n  dataId?: string;\n  store: NormalizedCache;\n  variables?: Object;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  /**\n   * Writes the result of a query to the store.\n   *\n   * @param result The result object returned for the query document.\n   *\n   * @param query The query document whose result we are writing to the store.\n   *\n   * @param store The {@link NormalizedCache} used by Apollo for the `data` portion of the store.\n   *\n   * @param variables A map from the name of a variable to its value. These variables can be\n   * referenced by the query document.\n   *\n   * @return A `Reference` to the written object.\n   */\n  public writeToStore({\n    query,\n    result,\n    dataId,\n    store,\n    variables,\n  }: WriteToStoreOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context: {\n        store,\n        written: Object.create(null),\n        merge<T>(existing: T, incoming: T) {\n          return merger.merge(existing, incoming) as T;\n        },\n        variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      },\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    const [id, keyObject] = policies.identify(\n      result, selectionSet, context.fragmentMap);\n\n    // If dataId was not provided, fall back to the id just generated by\n    // policies.identify.\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      const ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        ref,\n        selectionSet,\n        context,\n      )) {\n        return ref;\n      }\n    }\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incomingFields: StoreObject = Object.create(null);\n\n    // Write any key fields that were used during identification, even if\n    // they were not mentioned in the original query.\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        const resultFieldKey = resultKeyNameFromField(selection);\n        const value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          const storeFieldName = policies.getStoreFieldName({\n            typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n          });\n\n          const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          let incomingValue =\n            this.processFieldValue(value, selection, context, childTree);\n\n          const childTypename = selection.selectionSet\n            && context.store.getFieldValue<string>(incomingValue as StoreObject, \"__typename\")\n            || void 0;\n\n          const merge = policies.getMergeFunction(\n            typename,\n            selection.name.value,\n            childTypename,\n          );\n\n          if (merge) {\n            childTree.info = {\n              // TODO Check compatibility against any existing\n              // childTree.field?\n              field: selection,\n              typename,\n              merge,\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, {\n            [storeFieldName]: incomingValue,\n          });\n\n        } else if (\n          policies.usingPossibleTypes &&\n          !hasDirectives([\"defer\", \"client\"], selection)\n        ) {\n          throw new InvariantError(\n            `Missing field '${resultFieldKey}' in ${JSON.stringify(\n              result,\n              null,\n              2,\n            ).substring(0, 100)}`,\n          );\n        }\n      } else {\n        // This is not a field, so it must be a fragment, either inline or named\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.fragmentMap,\n        );\n\n        if (fragment &&\n            // By passing result and context.variables, we enable\n            // policies.fragmentMatches to bend the rules when typename is\n            // not a known subtype of the fragment type condition, but the\n            // result object contains all the keys requested by the\n            // fragment, which strongly suggests the fragment probably\n            // matched. This fuzzy matching behavior must be enabled by\n            // including a regular expression string (such as \".*\" or\n            // \"Prefix.*\" or \".*Suffix\") in the possibleTypes array for\n            // specific supertypes; otherwise, all matching remains exact.\n            // Fuzzy matches are remembered by the Policies object and\n            // later used when reading from the cache. Since there is no\n            // incoming result object to check when reading, reading does\n            // not involve the same fuzzy inference, so the StoreReader\n            // class calls policies.fragmentMatches without passing result\n            // or context.variables. The flexibility of fuzzy matching\n            // allows existing clients to accommodate previously unknown\n            // __typename strings produced by server/schema changes, which\n            // would otherwise be breaking changes.\n            policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets.has(fieldNameFromStoreName(storeFieldName));\n        const fieldsWithSelectionSets = new Set<string>();\n        workSet.forEach(selection => {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets.add(selection.name.value);\n          }\n        });\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              incomingFields,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n\n      return entityRef;\n    }\n\n    return incomingFields;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: ReadMergeModifyContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !Array.isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return Array.isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (Array.isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree &&\n      !childTree.info &&\n      !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!Array.isArray(existing) &&\n      !Array.isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}